{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4a823af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAJECTORY\n",
      " [array([[ 0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.]]), array([[ 0.,  0., -1.],\n",
      "       [-1.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.]]), array([[ 0.,  0., -1.],\n",
      "       [-1., -1.,  1.],\n",
      "       [ 0.,  0.,  1.]]), array([[ 1.,  0., -1.],\n",
      "       [-1., -1.,  1.],\n",
      "       [ 0., -1.,  1.]]), array([[ 1., -1., -1.],\n",
      "       [-1., -1.,  1.],\n",
      "       [ 1., -1.,  1.]])]\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "Reward to go:  -3.122\n",
      "\n",
      "State:\n",
      "[[ 0.  0. -1.]\n",
      " [-1.  0.  1.]\n",
      " [ 0.  0.  0.]]\n",
      "Reward to go:  -4.580000000000001\n",
      "\n",
      "State:\n",
      "[[ 0.  0. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "Reward to go:  -6.200000000000001\n",
      "\n",
      "State:\n",
      "[[ 1.  0. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 0. -1.  1.]]\n",
      "Reward to go:  -8.0\n",
      "\n",
      "State:\n",
      "[[ 1. -1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1. -1.  1.]]\n",
      "Reward to go:  -10.0\n",
      "\n",
      "TRAJECTORY\n",
      " [array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0., -1.],\n",
      "       [ 0.,  0.,  0.]]), array([[ 0.,  0.,  0.],\n",
      "       [ 1.,  0., -1.],\n",
      "       [-1.,  0.,  0.]]), array([[ 1.,  0., -1.],\n",
      "       [ 1.,  0., -1.],\n",
      "       [-1.,  0.,  0.]]), array([[ 1.,  0., -1.],\n",
      "       [ 1., -1., -1.],\n",
      "       [-1.,  0.,  1.]])]\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]]\n",
      "Reward to go:  -4.580000000000001\n",
      "\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 1.  0. -1.]\n",
      " [-1.  0.  0.]]\n",
      "Reward to go:  -6.200000000000001\n",
      "\n",
      "State:\n",
      "[[ 1.  0. -1.]\n",
      " [ 1.  0. -1.]\n",
      " [-1.  0.  0.]]\n",
      "Reward to go:  -8.0\n",
      "\n",
      "State:\n",
      "[[ 1.  0. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  0.  1.]]\n",
      "Reward to go:  -10.0\n",
      "\n",
      "TRAJECTORY\n",
      " [array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0., -1.]]), array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0., -1.],\n",
      "       [ 0.,  1., -1.]]), array([[ 1.,  0.,  0.],\n",
      "       [ 0., -1., -1.],\n",
      "       [ 0.,  1., -1.]]), array([[ 1., -1.,  0.],\n",
      "       [ 1., -1., -1.],\n",
      "       [ 0.,  1., -1.]]), array([[ 1., -1.,  0.],\n",
      "       [ 1., -1., -1.],\n",
      "       [ 1.,  1., -1.]])]\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "Reward to go:  3.439\n",
      "\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "Reward to go:  2.71\n",
      "\n",
      "State:\n",
      "[[ 1.  0.  0.]\n",
      " [ 0. -1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "Reward to go:  1.9\n",
      "\n",
      "State:\n",
      "[[ 1. -1.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  1. -1.]]\n",
      "Reward to go:  1.0\n",
      "\n",
      "TRAJECTORY\n",
      " [array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0., -1.]]), array([[ 0.,  1.,  0.],\n",
      "       [ 0., -1.,  0.],\n",
      "       [ 0.,  0., -1.]]), array([[ 1.,  1., -1.],\n",
      "       [ 0., -1.,  0.],\n",
      "       [ 0.,  0., -1.]]), array([[ 1.,  1., -1.],\n",
      "       [ 1., -1.,  0.],\n",
      "       [-1.,  0., -1.]])]\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "Reward to go:  -4.580000000000001\n",
      "\n",
      "State:\n",
      "[[ 0.  1.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "Reward to go:  -6.200000000000001\n",
      "\n",
      "State:\n",
      "[[ 1.  1. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "Reward to go:  -8.0\n",
      "\n",
      "State:\n",
      "[[ 1.  1. -1.]\n",
      " [ 1. -1.  0.]\n",
      " [-1.  0. -1.]]\n",
      "Reward to go:  -10.0\n",
      "\n",
      "TRAJECTORY\n",
      " [array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.]]), array([[ 0., -1.,  0.],\n",
      "       [ 0.,  0.,  1.],\n",
      "       [ 0., -1.,  0.]]), array([[ 1., -1., -1.],\n",
      "       [ 0.,  0.,  1.],\n",
      "       [ 0., -1.,  0.]]), array([[ 1., -1., -1.],\n",
      "       [ 0., -1.,  1.],\n",
      "       [ 1., -1.,  0.]])]\n",
      "State:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0. -1.  0.]]\n",
      "Reward to go:  -4.580000000000001\n",
      "\n",
      "State:\n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0. -1.  0.]]\n",
      "Reward to go:  -6.200000000000001\n",
      "\n",
      "State:\n",
      "[[ 1. -1. -1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0. -1.  0.]]\n",
      "Reward to go:  -8.0\n",
      "\n",
      "State:\n",
      "[[ 1. -1. -1.]\n",
      " [ 0. -1.  1.]\n",
      " [ 1. -1.  0.]]\n",
      "Reward to go:  -10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "DEFAULT_CONT = 1\n",
    "\n",
    "def get_open_spaces(board):\n",
    "    open_spaces = []\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[i])):\n",
    "            if (board[i][j] == 0):\n",
    "                open_spaces.append((i,j))\n",
    "    return open_spaces\n",
    "\n",
    "def is_winner(board, circle=True):\n",
    "    goal = len(board)\n",
    "    if (not circle):\n",
    "        goal *= -1\n",
    "\n",
    "    # Check rows\n",
    "    for i in range(len(board)):\n",
    "        if (sum(board[i]) == goal):\n",
    "            return True\n",
    "\n",
    "    # Check cols\n",
    "    for i in range(len(board[i])):\n",
    "        if (sum(board[:,i]) == goal):\n",
    "            return True\n",
    "\n",
    "    # Check diagonal\n",
    "    d1 = [board[x][x] for x in range(len(board))]\n",
    "    d2 = [board[x][len(board)-x-1] for x in range(len(board))]\n",
    "    if (sum(d1) == goal or sum(d2) == goal):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def get_reward(board, num_open_spaces, cont):\n",
    "    if (is_winner(board, True)): # Player wins\n",
    "        return 10\n",
    "    if (is_winner(board, False)): # Opponent wins\n",
    "        return -10\n",
    "    if (num_open_spaces == 0):\n",
    "        return 0\n",
    "    return cont\n",
    "\n",
    "def random_move(board, open_spaces, isplayer):\n",
    "    if isplayer:\n",
    "        marker = 1\n",
    "    else:\n",
    "        marker = -1\n",
    "    index = np.random.randint(0, len(open_spaces))\n",
    "    board[open_spaces[index]] = marker\n",
    "\n",
    "def calculate_rewardtogo(reward, discount):\n",
    "    rewardtogo = [0. for i in range(len(reward))] \n",
    "    for i in range(len(reward)):\n",
    "        for j in range(i, len(reward)):\n",
    "            rewardtogo[i] += reward[j] * discount ** (j-i)\n",
    "    return rewardtogo\n",
    "\n",
    "def MDP(board):\n",
    "    states = []\n",
    "    reward = [] # reward at each state\n",
    "    player_turn = False\n",
    "    while (True):\n",
    "        open_spaces = get_open_spaces(board)\n",
    "        r = get_reward(board, len(open_spaces), DEFAULT_CONT)\n",
    "        if player_turn:\n",
    "            states.append(copy.deepcopy(board))\n",
    "            reward.append(r)\n",
    "        if (r != 1): # Game over\n",
    "            if r == 10:\n",
    "                states.append(copy.deepcopy(board))\n",
    "                #reward.append(r) state and reward before terminal cases\n",
    "                \n",
    "            break\n",
    "        random_move(board, open_spaces, player_turn)\n",
    "        if player_turn:\n",
    "            player_turn = False\n",
    "        else:\n",
    "            player_turn = True\n",
    "    return reward, states\n",
    "\n",
    "init_board = np.zeros((3,3))\n",
    "discount = 0.9\n",
    "seeds = [6,1,2,3,4]\n",
    "for i in range(len(seeds)):\n",
    "    np.random.seed(seeds[i])\n",
    "    board = copy.deepcopy(init_board)\n",
    "    reward,states = MDP(board)\n",
    "    rewardtogo = calculate_rewardtogo(reward, discount)\n",
    "    print('TRAJECTORY\\n', states)\n",
    "    for i in range(len(rewardtogo)):\n",
    "        print('State:')\n",
    "        print(states[i])\n",
    "        print('Reward to go: ', rewardtogo[i])\n",
    "        print('')\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98a2fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_states(board, all_states, turn, cont):\n",
    "    skip = False\n",
    "    if turn:\n",
    "        board_str = np.array2string(board)\n",
    "        if board_str in all_states:\n",
    "            skip = True\n",
    "        else:\n",
    "            all_states[board_str] = copy.deepcopy(board)\n",
    "    open_spaces = get_open_spaces(board)\n",
    "    r = get_reward(board, len(open_spaces), cont)\n",
    "    if r == cont or not skip: # Game is not over\n",
    "        for i in open_spaces:\n",
    "            if turn:\n",
    "                board[i] = 1\n",
    "            else:\n",
    "                board[i] = -1\n",
    "            get_all_states(copy.deepcopy(board), all_states, not turn, cont)\n",
    "            board[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "585e3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def value_iteration(init_board, discount, cont, target):\n",
    "    all_states = {}\n",
    "    board = copy.deepcopy(init_board)\n",
    "    get_all_states(board, all_states, False, cont)\n",
    "\n",
    "    new_values = {k:0 for k in all_states}\n",
    "    it = 0\n",
    "    res = collections.defaultdict(lambda:[0])\n",
    "    while (True):\n",
    "        values = copy.deepcopy(new_values)\n",
    "        delta = 0\n",
    "        for s in all_states.keys():\n",
    "            curr_state = copy.deepcopy(all_states[s])\n",
    "            open_spaces = get_open_spaces(curr_state)\n",
    "            r = get_reward(curr_state, len(open_spaces), cont)\n",
    "            # Get max player action\n",
    "            best_action = 0.\n",
    "            if r == cont:\n",
    "                if it == 0:\n",
    "                    # initial reward -> optimal value\n",
    "                    res[s].append(r)\n",
    "                for i in range(len(open_spaces)):\n",
    "                    curr_action = 0.\n",
    "                    num_pos = 0.\n",
    "                    for j in range(len(open_spaces)):\n",
    "                        if (i != j):\n",
    "                            num_pos += 1\n",
    "                            player_move = open_spaces[i]\n",
    "                            opponent_move = open_spaces[j]\n",
    "                            tmp_state = copy.deepcopy(curr_state)\n",
    "                            tmp_state[player_move] = 1\n",
    "                            tmp_state[opponent_move] = -1\n",
    "                            board_str = np.array2string(tmp_state)\n",
    "                            if (board_str in values):\n",
    "                                curr_action += values[board_str]\n",
    "                    curr_action = curr_action / num_pos\n",
    "                    if (curr_action > best_action):\n",
    "                        best_action = curr_action \n",
    "            # Set updated value\n",
    "            new_values[s] = r + discount * best_action\n",
    "      \n",
    "            if res[s][-1] is None:\n",
    "                continue\n",
    "            res[s].append(new_values[s])\n",
    "\n",
    "            value_change = abs(new_values[s] - values[s])\n",
    "            if value_change < 0.1:\n",
    "                res[s].append(None)\n",
    "            if value_change > delta\n",
    "                delta = abs(new_values[s] - values[s])\n",
    "\n",
    "        if (delta < 0.1):\n",
    "            break\n",
    "        it += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71233a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907\n",
      "it 0\n",
      "1.0 1.0\n",
      "delta 10.0\n",
      "it 1\n",
      "10.0 9.0\n",
      "delta 9.0\n",
      "it 2\n",
      "10.0 0.0\n",
      "delta 8.1\n",
      "it 3\n",
      "10.0 0.0\n",
      "delta 5.977799999999999\n",
      "it 4\n",
      "10.0 0.0\n",
      "delta 1.0483714285714303\n",
      "it 5\n",
      "10.0 0.0\n",
      "delta 0\n",
      "BREAK 5 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "board = copy.deepcopy(init_board)\n",
    "target = np.array([[-1.,0.,-1.], [1.,1.,0.], [ -1.,  0., 0.]])\n",
    "target_string = np.array2string(target)\n",
    "values = value_iteration(board, discount, DEFAULT_CONT,target_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "746fd32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1.0, None]\n"
     ]
    }
   ],
   "source": [
    "print(values[target_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b5dc0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "target = np.array([[-1.,0.,-1.], [1.,1.,0.], [ -1.,  0., 0.]])\n",
    "target_string = np.array2string(target)\n",
    "\n",
    "print(values[target_string],target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ce6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
